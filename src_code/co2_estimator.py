# -*- coding: utf-8 -*-
"""Co2_estimator.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1geoUwVoxScrHhIQZzWGU51MMJTfRgCkC
"""

# Import necessary libraries
import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline
import gdown

# **Step 1: Load Dataset**
file_id = "1ZbR2jioaBxLJEBHQ3OWdbOcRBrdKjRx2"
gdown.download(f"https://drive.google.com/uc?id={file_id}", "dataset.csv", quiet=False)

df = pd.read_csv("dataset.csv")



#file_path = "https://drive.google.com/file/d/1ZbR2jioaBxLJEBHQ3OWdbOcRBrdKjRx2/view?usp=sharing"  # Ensure correct path
#df = pd.read_csv(file_path)

# **Step 2: Define Feature Selection Function**
def prepare_data(model_name):
    # Define feature sets for different AI models
    feature_sets = {
        "co2_emission": {
            "X": ["Excavation", "Transportation", "Fuel", "Equipment", "Workers", "FuelType", "Reduction"],
            "y": "CO2_Emissions_MtCO2e"
        }
    }

    if model_name not in feature_sets:
        raise ValueError("Invalid model name!")

    features = feature_sets[model_name]["X"]
    target = feature_sets[model_name]["y"]

    # Select relevant features
    X = df[features]
    y = df[target]

    # Identify categorical and numerical columns
    categorical_features = X.select_dtypes(include=["object"]).columns.tolist()
    numerical_features = X.select_dtypes(exclude=["object"]).columns.tolist()

    # Preprocessing pipeline
    num_pipeline = StandardScaler()
    cat_pipeline = OneHotEncoder(handle_unknown="ignore")

    preprocessor = ColumnTransformer([
        ("num", num_pipeline, numerical_features),
        ("cat", cat_pipeline, categorical_features)
    ])

    # Split data into train-test sets (80-20 split)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Fit and transform preprocessing
    X_train = preprocessor.fit_transform(X_train)
    X_test = preprocessor.transform(X_test)

    # Save preprocessor for future predictions
    joblib.dump(preprocessor, "co2_emission_preprocessor.pkl")

    return X_train, X_test, y_train, y_test

# **Step 3: Train COâ‚‚ Emission Model**
def train_co2_emission_model():
    print("ðŸ”¹ Training COâ‚‚ Emission Model...")

    # Prepare data
    X_train, X_test, y_train, y_test = prepare_data("co2_emission")

    # Train model
    rf_model = RandomForestRegressor(n_estimators=300, max_depth=15, random_state=42)
    rf_model.fit(X_train, y_train)

    # Save model
    joblib.dump(rf_model, "co2_emission_model.pkl")

    print("âœ… Model trained and saved successfully!")

# **Step 4: Take User Input for Prediction**
def get_user_input():
    print("\nðŸ”¹ Enter mining operation details:")
    excavation = float(input("Excavation Volume (thousand mÂ³): "))
    transportation = float(input("Transportation Distance (km): "))
    fuel = float(input("Fuel Consumption (thousand liters): "))
    equipment = float(input("Equipment Usage (hours): "))
    workers = int(input("Number of Workers: "))
    fuelType = input("Fuel Type (coal/diesel/gas): ")
    reduction = float(input("Emission Reduction (%): "))

    return pd.DataFrame([[excavation, transportation, fuel, equipment, workers, fuelType, reduction]],
                        columns=["Excavation", "Transportation", "Fuel", "Equipment", "Workers", "FuelType", "Reduction"])

# **Step 5: Predict COâ‚‚ Emissions for New Data**
def predict_emission():
    user_input = get_user_input()

    # Load preprocessor and model
    preprocessor = joblib.load("co2_emission_preprocessor.pkl")
    model = joblib.load("co2_emission_model.pkl")

    # Preprocess user input
    user_input_transformed = preprocessor.transform(user_input)

    # Predict COâ‚‚ emissions
    predicted_emission = model.predict(user_input_transformed)[0]

    print(f"\nðŸ”¹ **Predicted COâ‚‚ Emission:** {predicted_emission:.2f} metric tons")

# **Step 6: Visualize COâ‚‚ Emission Trends**
def visualize_emission_trends():
    plt.figure(figsize=(10, 6))
    sns.histplot(df["CO2_Emissions_MtCO2e"], bins=20, kde=True, color="blue")
    plt.title("Distribution of COâ‚‚ Emissions")
    plt.xlabel("COâ‚‚ Emissions (MtCO2e)")
    plt.ylabel("Frequency")
    plt.show()

    plt.figure(figsize=(12, 6))
    sns.boxplot(x="FuelType", y="CO2_Emissions_MtCO2e", data=df, palette="Set2")
    plt.title("COâ‚‚ Emissions by Fuel Type")
    plt.show()

# **Step 7: Run Program**
if __name__ == "__main__":
    train_co2_emission_model()  # Train the model (Only run this once)
    predict_emission()  # Take user input and predict COâ‚‚ emissions
    visualize_emission_trends()  # Show emission trends